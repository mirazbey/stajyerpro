"""
GeliÅŸmiÅŸ HMGS Soru Ãœretim Sistemi
- Konu bazlÄ± multi-PDF iÅŸleme
- Tekrar tespit (deduplication)
- Progress tracking & resume
- AkÄ±llÄ± chunking
"""

import os
import json
import yaml
import hashlib
import argparse
from pathlib import Path
from typing import List, Dict
from datetime import datetime
import google.generativeai as genai
from PyPDF2 import PdfReader
import firebase_admin
from firebase_admin import credentials, firestore
from difflib import SequenceMatcher

# Gemini API
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
if not GEMINI_API_KEY:
    print("âš ï¸ GEMINI_API_KEY environment variable bulunamadÄ±!")
    exit(1)

genai.configure(api_key=GEMINI_API_KEY)

class QuestionGenerator:
    def __init__(self, config_file: str):
        """KonfigÃ¼rasyon dosyasÄ±nÄ± yÃ¼kle"""
        with open(config_file, 'r', encoding='utf-8') as f:
            self.config = yaml.safe_load(f)
        
        self.docs_dir = Path(self.config['settings']['docs_directory'])
        self.output_dir = Path(self.config['settings']['output_directory'])
        self.output_dir.mkdir(exist_ok=True)
        
        self.progress_file = self.output_dir / "progress.json"
        self.progress = self.load_progress()
        
        # Firestore baÄŸlantÄ±sÄ± (deduplication iÃ§in)
        self.db = None
        if self.config['settings']['enable_deduplication']:
            self.init_firebase()
    
    def init_firebase(self):
        """Firebase'i baÅŸlat (deduplication iÃ§in)"""
        try:
            cred_path = "serviceAccountKey.json"
            if os.path.exists(cred_path):
                cred = credentials.Certificate(cred_path)
                firebase_admin.initialize_app(cred)
                self.db = firestore.client()
                print("âœ… Firebase baÄŸlantÄ±sÄ± kuruldu (deduplication aktif)")
        except:
            print("âš ï¸ Firebase baÄŸlanamadÄ±, deduplication devre dÄ±ÅŸÄ±")
            self.db = None
    
    def load_progress(self) -> Dict:
        """Ä°lerleme dosyasÄ±nÄ± yÃ¼kle"""
        if self.progress_file.exists():
            with open(self.progress_file, 'r') as f:
                return json.load(f)
        return {}
    
    def save_progress(self):
        """Ä°lerlemeyi kaydet"""
        with open(self.progress_file, 'w') as f:
            json.dump(self.progress, f, indent=2)
    
    def extract_text_from_multiple_pdfs(self, pdf_files: List[str], max_pages: int) -> str:
        """Birden fazla PDF'i birleÅŸtirip metin Ã§Ä±kar"""
        combined_text = ""
        
        for pdf_file in pdf_files:
            pdf_path = self.docs_dir / pdf_file
            
            if not pdf_path.exists():
                print(f"âš ï¸ PDF bulunamadÄ±: {pdf_file}")
                continue
            
            print(f"  ğŸ“„ Okunuyor: {pdf_file}")
            
            try:
                reader = PdfReader(str(pdf_path))
                total_pages = len(reader.pages)
                pages_to_read = min(total_pages, max_pages)
                
                for i in range(pages_to_read):
                    page = reader.pages[i]
                    combined_text += page.extract_text() + "\n\n"
                
                print(f"     âœ… {pages_to_read}/{total_pages} sayfa okundu")
            
            except Exception as e:
                print(f"     âŒ Hata: {e}")
        
        return combined_text
    
    def chunk_text(self, text: str, chunk_size: int) -> List[str]:
        """Metni akÄ±llÄ±ca parÃ§alara bÃ¶l (paragraf sÄ±nÄ±rlarÄ±nÄ± koruyarak)"""
        paragraphs = text.split('\n\n')
        chunks = []
        current_chunk = []
        current_length = 0
        
        for para in paragraphs:
            para_length = len(para)
            
            if current_length + para_length > chunk_size and current_chunk:
                # Chunk doldu, kaydet
                chunks.append('\n\n'.join(current_chunk))
                current_chunk = [para]
                current_length = para_length
            else:
                current_chunk.append(para)
                current_length += para_length
        
        if current_chunk:
            chunks.append('\n\n'.join(current_chunk))
        
        return chunks
    
    def generate_question_hash(self, question_stem: str) -> str:
        """Soru iÃ§in benzersiz hash oluÅŸtur (deduplication iÃ§in)"""
        # Soruyu normalize et (kÃ¼Ã§Ã¼k harf, boÅŸluk temizle)
        normalized = question_stem.lower().strip()
        normalized = ' '.join(normalized.split())  # Ã‡oklu boÅŸluklarÄ± tek boÅŸluk yap
        return hashlib.md5(normalized.encode()).hexdigest()
    
    def is_duplicate_question(self, question_stem: str, subject_id: str) -> bool:
        """Firestore'da benzer soru var mÄ± kontrol et"""
        if not self.db:
            return False
        
        try:
            # Ã–nce hash ile exact match kontrol
            question_hash = self.generate_question_hash(question_stem)
            
            # Firestore'dan bu konuyla ilgili tÃ¼m sorularÄ± Ã§ek
            questions_ref = self.db.collection('questions').where('subjectId', '==', subject_id).limit(500)
            existing_questions = questions_ref.stream()
            
            threshold = self.config['settings']['similarity_threshold']
            
            for doc in existing_questions:
                existing_stem = doc.to_dict().get('stem', '')
                
                # Similarity check
                similarity = SequenceMatcher(None, question_stem.lower(), existing_stem.lower()).ratio()
                
                if similarity > threshold:
                    print(f"     ğŸ” Benzer soru bulundu (benzerlik: {similarity:.2%})")
                    return True
            
            return False
        
        except Exception as e:
            print(f"     âš ï¸ Deduplication hatasÄ±: {e}")
            return False
    
    def generate_questions_with_gemini(self, text: str, subject_info: Dict, num_questions: int) -> List[Dict]:
        """Gemini ile soru Ã¼ret"""
        
        prompt = f"""
Sen bir HMGS (Hukuk Mesleklerine GiriÅŸ SÄ±navÄ±) soru yazarÄ±sÄ±n.

KONU: {subject_info['name']}
SUBJECT ID: {subject_info['subjectId']}

AÅŸaÄŸÄ±daki {subject_info['name']} metninden **{num_questions} adet** HMGS tarzÄ± soru Ã¼ret:

---
{text[:10000]}  # Ä°lk 10000 karakter (Gemini input limit)
---

KURALLAR:
1. Sorular **{subject_info['name']}** konusuyla ilgili olmalÄ±
2. Her soru 5 ÅŸÄ±klÄ± (A-E)
3. Ã‡eldirici ÅŸÄ±klar gerÃ§ekÃ§i olmalÄ±
4. Kanun maddesi referansÄ± ekle (varsa)
5. DetaylÄ± aÃ§Ä±klama + yanlÄ±ÅŸ ÅŸÄ±k sebepleri

JSON FORMAT:
```json
[
  {{
    "stem": "Soru metni...",
    "options": ["A", "B", "C", "D", "E"],
    "correctIndex": 0,
    "difficulty": "medium",
    "lawArticle": "TMK m. 186",
    "detailedExplanation": "...",
    "wrongReasons": {{"1": "B yanlÄ±ÅŸ Ã§Ã¼nkÃ¼...", "2": "C yanlÄ±ÅŸ Ã§Ã¼nkÃ¼..."}},
    "subjectId": "{subject_info['subjectId']}",
    "topicIds": []
  }}
]
```

SADECE JSON VER.
"""
        
        try:
            model = genai.GenerativeModel('gemini-2.0-flash-exp')
            response = model.generate_content(prompt)
            
            # JSON parse
            response_text = response.text.strip()
            
            # Markdown temizle
            if response_text.startswith("```json"):
                response_text = response_text[7:]
            if response_text.startswith("```"):
                response_text = response_text[3:]
            if response_text.endswith("```"):
                response_text = response_text[:-3]
            
            questions = json.loads(response_text.strip())
            
            # Deduplication kontrolÃ¼
            unique_questions = []
            for q in questions:
                if not self.is_duplicate_question(q['stem'], subject_info['subjectId']):
                    unique_questions.append(q)
                else:
                    print(f"     â­ï¸  Tekrar soru atlandÄ±")
            
            return unique_questions
        
        except Exception as e:
            print(f"     âŒ Gemini hatasÄ±: {e}")
            return []
    
    def process_subject(self, subject_key: str):
        """Bir dersi iÅŸle (tÃ¼m PDF'leri birleÅŸtirerek)"""
        subject_info = self.config['subjects'][subject_key]
        
        print(f"\n{'='*70}")
        print(f"ğŸ“š {subject_info['name']} Ä°ÅŸleniyor")
        print(f"{'='*70}")
        
        # Progress kontrolÃ¼
        if subject_key in self.progress and self.progress[subject_key].get('completed', False):
            print(f"âœ… Bu ders zaten iÅŸlenmiÅŸ, atlanÄ±yor.")
            response = input("Yine de iÅŸlemek ister misin? (y/n): ")
            if response.lower() != 'y':
                return
        
        # PDF'leri birleÅŸtir
        print(f"\nğŸ“– {len(subject_info['pdfs'])} PDF birleÅŸtiriliyor...")
        combined_text = self.extract_text_from_multiple_pdfs(
            subject_info['pdfs'],
            self.config['settings']['max_pages_per_pdf']
        )
        
        if not combined_text:
            print("âŒ HiÃ§ metin Ã§Ä±karÄ±lamadÄ±!")
            return
        
        print(f"âœ… Toplam {len(combined_text):,} karakter metin")
        
        # Chunk'lara bÃ¶l
        chunks = self.chunk_text(combined_text, self.config['settings']['chunk_size'])
        print(f"ğŸ“¦ {len(chunks)} parÃ§aya bÃ¶lÃ¼ndÃ¼")
        
        # Her chunk iÃ§in soru Ã¼ret
        all_questions = []
        target_questions = subject_info['target_questions']
        questions_per_chunk = self.config['settings']['questions_per_chunk']
        
        for i, chunk in enumerate(chunks):
            if len(all_questions) >= target_questions:
                print(f"\nğŸ¯ Hedef soru sayÄ±sÄ±na ulaÅŸÄ±ldÄ± ({target_questions}), durduruluyor.")
                break
            
            print(f"\n--- Chunk {i+1}/{len(chunks)} ---")
            questions = self.generate_questions_with_gemini(chunk, subject_info, questions_per_chunk)
            all_questions.extend(questions)
            print(f"âœ… Åu ana kadar: {len(all_questions)} soru")
        
        # JSON olarak kaydet
        output_file = self.output_dir / f"{subject_key}_questions.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(all_questions, f, ensure_ascii=False, indent=2)
        
        # Progress gÃ¼ncelle
        self.progress[subject_key] = {
            'completed': True,
            'questions_generated': len(all_questions),
            'timestamp': datetime.now().isoformat()
        }
        self.save_progress()
        
        print(f"\nâœ… {subject_info['name']}: {len(all_questions)} soru Ã¼retildi")
        print(f"ğŸ’¾ Kaydedildi: {output_file}")

def main():
    parser = argparse.ArgumentParser(description='GeliÅŸmiÅŸ Soru Ãœretim Sistemi')
    parser.add_argument('--config', type=str, default='scripts/subject_config.yaml', help='KonfigÃ¼rasyon dosyasÄ±')
    parser.add_argument('--subject', type=str, help='Tek ders iÅŸle (Ã¶rn: medeni_hukuk)')
    parser.add_argument('--all', action='store_true', help='TÃ¼m dersleri iÅŸle')
    
    args = parser.parse_args()
    
    generator = QuestionGenerator(args.config)
    
    if args.all:
        # TÃ¼m dersleri iÅŸle
        for subject_key in generator.config['subjects'].keys():
            generator.process_subject(subject_key)
    elif args.subject:
        # Tek ders iÅŸle
        if args.subject in generator.config['subjects']:
            generator.process_subject(args.subject)
        else:
            print(f"âŒ '{args.subject}' dersi bulunamadÄ±!")
            print(f"Mevcut dersler: {', '.join(generator.config['subjects'].keys())}")
    else:
        print("âš ï¸ --subject veya --all parametresi gerekli!")
        print("Ã–rnek: python advanced_question_generator.py --subject medeni_hukuk")

if __name__ == "__main__":
    main()
